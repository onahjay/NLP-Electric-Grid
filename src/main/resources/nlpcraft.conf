#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#
# This is joint configuration file for both the server and the data probes. Note that
# server and probe configuration can be placed into separate files. You can also provide
# configuration properties or override the default ones via environment variables.
#
# To use environment vairables:
# 1. Set probe or server JVM system property -Dconfig.override_with_env_vars=true
# 2. For each configuration 'x.y.z' set the environment variable CONFIG_FORCE_x_y_z=some_value
#
# Examples of environment variable usage:
#   CONFIG_FORCE_nlpcraft_server_rest_host=localhost
#   CONFIG_FORCE_nlpcraft_server_lifecycle.0=org.apache.nlpcraft.server.lifecycle.opencensus.NCStackdriverTraceExporter
#   CONFIG_FORCE_nlpcraft_server_lifecycle.1=org.apache.nlpcraft.server.lifecycle.opencensus.NCStackdriverStatsExporter
#
# See https://nlpcraft.apache.org/server-and-probe.html for more details.
#

# Common server/probe configuration root.
nlpcraft {
    # +---------------------------------+
    # | REST server configuration root. |
    # +---------------------------------+
    server {
        # Specify class names for server lifecycle components.
        # Each class should implement 'NCServerLifecycle' interface/trait and provide an no-arg constructor.
        #
        # The following built-in OpenCensus exporters are supported as lifecycle components:
        # - org.apache.nlpcraft.server.lifecycle.opencensus.NCJaegerExporter (traces)
        # - org.apache.nlpcraft.server.lifecycle.opencensus.NCZipkinExporter (traces)
        # - org.apache.nlpcraft.server.lifecycle.opencensus.NCPrometheusExporter (stats)
        # - org.apache.nlpcraft.server.lifecycle.opencensus.NCStackdriverTraceExporter (traces)
        # - org.apache.nlpcraft.server.lifecycle.opencensus.NCStackdriverStatsExporter (stats)
        #
        # NOTE: all built-in trace exporters use "always" sampling that is only suitable
        # for demo or development purposes. For production usage you need to modify the
        # sampling strategy: https://opencensus.io/tracing/sampling/
        lifecycle = [
        ]

        # Properties for various OpenCensus built-in exporters.
        # All configuratin properties are optional unless otherwise specified.
        # opencensus {
        #     jaeger {
        #         thriftUrl = "http://127.0.0.1:14268/api/traces"
        #         serviceName = "nlpcraft-server"
        #     }
        #     prometheus {
        #         hostPort = "localhost:8888"
        #         namespace = "nlpcraft-server"
        #     }
        #     stackdriver {
        #         # Mandatory Google project ID.
        #         googleProjectId = "your_google_project_id"
        #         metricsPrefix = "custom.googleapis.com/nlpcraft/server"
        #     }
        #     zipkin {
        #         v2Url = "http://127.0.0.1:9411/api/v2/spans"
        #         serviceName = "nlpcraft-server"
        #     }
        # }

        # Apache Ignite database, which is used by default, doesn't require configuration.
        # MySql, Postgres and Oracle databases can be configured instead.
        database {
            # jdbc {
            #     # MySQL URL and driver.
            #     # Note that MySQL driver dependencies should be added to the project,
            #     # and scripts sql/mysql should be executed.
            #     # Tested under MySQL 5.7.17.
            #     url = "jdbc:mysql://localhost:3306/nlpcraft"
            #     driver = com.mysql.jdbc.Driver
            #     username = <user>
            #     password = <password>
            # }

            # jdbc {
            #     # Postgres URL and driver.
            #     # Note that Postgres driver dependencies should be added to the project,
            #     # and scripts sql/postgres should be executed.
            #     # Tested under Postgres 9.6.9.
            #     url = "jdbc:postgresql://localhost:5432/nlpcraft"
            #     driver = org.postgresql.Driver
            #     username = nlpcraft
            #     password = nlpcraft
            # }

            # jdbc {
            #     # Oracle URL and driver.
            #     # Note that Oracle driver dependencies should be added to the project,
            #     # and scripts sql/oracle should be executed.
            #     # Tested under Oracle 11G (XE).
            #     url = "jdbc:oracle:thin:@localhost:1521:XE"
            #     driver = oracle.jdbc.driver.OracleDriver
            #     username = nlpcraft
            #     password = nlpcraft
            # }

            # Apache Ignite In-Memory Computing Platform (persistence).
            jdbc {
                # Ignite JDBC URL and driver.
                url = "jdbc:ignite:thin://127.0.0.1/nlpcraft"
                driver = org.apache.ignite.IgniteJdbcThinDriver
                # username =
                # password =
            }

            # Only used when Apache Ignite is configured as persistence provider.
            # Allows to reset Ignite DB.
            igniteDbInitialize = false

            # Common JDBC connection pool for any supported database.
            c3p0 {
                maxStatements = 180

                pool {
                    initSize = 10
                    minSize = 1
                    maxSize = 50
                    acquireIncrement = 2
                }
            }
        }

        # REST server configuration.
        rest {
            # NOTE: 'localhost' or '127.0.0.1' don't work from Docker container.
            host = "0.0.0.0"
            port = 8081
            apiImpl = "org.apache.nlpcraft.server.rest.NCBasicRestApi"
        }

        # User manager configuration.
        user {
            pwdPoolBlowup = 3
            timeoutScannerFreqMins = 1
            accessTokenExpireTimeoutMins = 60
        }

        # Probe manager configuration.
        probe {
            links {
                # Default endpoints.
                #
                # NOTES:
                # ------
                # (1) If changed - they need to be changed on both server and probes.
                # (2) Don't use 'localhost' if server and probe(s) are on different hosts.
                # (3) Use "0.0.0.0" IP address when running server in a docker container.

                # This property can be overridden with system property.
                upLink = "0.0.0.0:8201" # Server to probe data pipe.

                # This property can be overridden with system property.
                downLink = "0.0.0.0:8202" # Probe to server data pipe.
            }

            pingTimeoutMs = 2000
            soTimeoutMs = 5000
            reconnectTimeoutMs = 5000
            poolSize = 100
        }

        # Default date formatting for 'nlpcraft:date' token detection only.
        # Supported formats: MDY, DMY, YMD.
        datesFormatStyle = MDY

        # Enabled built-in token providers (each token represents a named entity).
        # User models can only use built-in tokens from the token providers configured here.
        #
        # Supported values:
        # * 'nlpcraft' - Built-in NLPCraft tokens. Token IDs start with 'nlpcraft:'.
        # * 'opennlp' - Apache OpenNLP (https://opennlp.apache.org). Token IDs start with 'opennlp:'.
        # * 'stanford' - Stanford CoreNLP (https://stanfordnlp.github.io/CoreNLP). Token IDs start with 'stanford:'.
        # * 'google' - Google Natural Language (https://cloud.google.com/natural-language). Token IDs start with 'google:'.
        # * 'spacy' - Python NLP Library (https://spacy.io). Token IDs start with 'spacy:'.
        #
        # DO NOT confuse these token providers with underlying NLP engine ('opnenlp' or 'stanford').
        # NLP engine is used only for the basic NLP processing such as tokenization, lemmatization, etc.
        # NLP engines and supported token providers can be mixed and matched, i.e. 'stanford' NLP engine
        # can be used with 'google' and 'opennlp' token providers.
        #
        # See Integrations section (https://nlpcraft.apache.org/integrations.html) for details on how to
        # configure 3rd party token providers.
        tokenProviders = [
            nlpcraft # By default - only NLPCraft tokens are enabled and can be used by the user data models.
        ]

        # If Spacy is enabled as a token provider (value 'spacy') - defines Spacy proxy URL.
        # spacy.proxy.url=http://localhost:5002
    }

    # +------------------------------------------+
    # | Probe configuration with example models. |
    # +------------------------------------------+
    probe {
        # Any arbitrary descriptive name.
        id = "all.examples"

        # This is the default token (as in default company).
        # Note that this token must match the probe token for the company this probe
        # associated with. If changed from default, this token must be kept secure.
        token = "3141592653589793"

        # These are default up-link and down-link endpoints that the probe will connect to.
        # If changed - they need to be changed on both server and probe.
        upLink = "localhost:8201"   # Server to probe data pipe.
        downLink = "localhost:8202" # Probe to server data pipe.

        # All JARs in this folder will be scanned for models.
        # Safely ignored if 'null' - but then 'models' should have at least one element.
        jarsFolder = null

        # Fully qualified class names for models that will be instantiated.
        # Must be on the active class path for the probe.
        # Can be empty but then 'jarsFolder' must be provided.
        models = [
            # Example of listing model for probe to start with.
            "org.apache.nlpcraft.examples.echo.EchoModel"

            # Note that following models requires 'google' on the server side.
            # See https://nlpcraft.apache.org/integrations.html#nlp for more details
            # on how to configure 3rd party token providers.
            # "org.apache.nlpcraft.examples.phone.PhoneModel"
        ]

        # Specify class names for probe life cycle components.
        # Each class should extend 'NCProbeLifecycle' interface and provide a no-arg constructor.
        #
        # The following built-in OpenCensus exporters are supported as lifecycle components:
        # - org.apache.nlpcraft.model.opencensus.NCJaegerExporter (traces)
        # - org.apache.nlpcraft.model.opencensus.NCZipkinExporter (traces)
        # - org.apache.nlpcraft.model.opencensus.NCPrometheusExporter (stats)
        # - org.apache.nlpcraft.model.opencensus.NCStackdriverTraceExporter (traces)
        # - org.apache.nlpcraft.model.opencensus.NCStackdriverStatsExporter (stats)
        lifecycle = [
        ]

        # Properties for built-in OpenCensus exporters.
        # All configuratin properties are optional unless otherwise specified.
        # opencensus {
        #     jaeger {
        #         thriftUrl = "http://127.0.0.1:14268/api/traces"
        #         serviceName = "nlpcraft-probe"
        #     }
        #     prometheus {
        #         hostPort = "localhost:8889"
        #         namespace = "nlpcraft-probe"
        #     }
        #     stackdriver {
        #         # Mandatory Google project ID.
        #         googleProjectId = "your_google_project_id"
        #         metricsPrefix = "custom.googleapis.com/nlpcraft/probe"
        #     }
        #     zipkin {
        #         v2Url = "http://127.0.0.1:9411/api/v2/spans"
        #         serviceName = "nlpcraft-probe"
        #     }
        # }

        # Maximum execution result size in bytes. Default value is 1M.
        # When exceeded the request will be automatically rejected.
        resultMaxSizeBytes = 1048576
    }

    # Basic NLP tooklit to use on both server and probes. Possible values:
    # - 'opennlp'
    # - 'stanford'
    #
    # NOTE: Stanford CoreNLP requires special installation due to its licensing.
    # See https://nlpcraft.apache.org/integrations.html#stanford for more details.
    nlpEngine = "opennlp"

    # Disable anonymous version check.
    versionCheckDisable = false
}
